{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function, division\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import functools\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "import os\n",
    "import time\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size: 96675\n",
      "# of train class:  20\n",
      "# of valid class:  20\n",
      "# of test class :  20\n",
      "train_size:  67672 \n",
      "valid_size:  19335 \n",
      "test_size :  9668\n"
     ]
    }
   ],
   "source": [
    "#%% 이걸 사용하자\n",
    "t_image_size=224\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(t_image_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(t_image_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(t_image_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_dir = '/media/lee/E61C94F21C94BECD/place_dataset/Places2/data_256/20'\n",
    "# data_dir = '/media/lee/E61C94F21C94BECD/place_dataset/Places2/data_class50/'\n",
    "\n",
    "\n",
    "train_image_datasets = torchvision.datasets.ImageFolder(os.path.join(data_dir),\n",
    "                                     transform = transform_train)\n",
    "val_image_datasets = torchvision.datasets.ImageFolder(os.path.join(data_dir),\n",
    "                                     transform = transform_val)\n",
    "test_image_datasets = torchvision.datasets.ImageFolder(os.path.join(data_dir),\n",
    "                                     transform = transform_test)\n",
    "\n",
    "\n",
    "dataset_size = len(train_image_datasets)\n",
    "print('total size:', dataset_size)\n",
    "class_names_train = train_image_datasets.classes\n",
    "class_names_val = val_image_datasets.classes\n",
    "class_names_test = test_image_datasets.classes\n",
    "# print(class_names)\n",
    "print('# of train class: ', len(class_names_train))\n",
    "print('# of valid class: ', len(class_names_val))\n",
    "print('# of test class : ', len(class_names_test))\n",
    "## SPLIT DATASET\n",
    "train_split= 0.7\n",
    "validate_split = 0.20\n",
    "test_split = 0.10\n",
    "train_size = int(train_split * dataset_size)\n",
    "validation_size = int(validate_split * dataset_size)\n",
    "test_size = int(dataset_size - train_size - validation_size)\n",
    "\n",
    "# ########### CURRENTLY DOING THIS, WHICH WORKS ###########\n",
    "\n",
    "indices = list(range(dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "train_indices = indices[:train_size]\n",
    "temp = int(train_size+validation_size)\n",
    "val_indices = indices[train_size:temp]\n",
    "test_indices = indices[temp:]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_image_datasets, batch_size=batch_size, sampler=train_sampler,\n",
    "    num_workers=4)\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    val_image_datasets, batch_size=batch_size, sampler=valid_sampler,\n",
    "    num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_image_datasets, batch_size=batch_size, sampler=test_sampler,\n",
    "    num_workers=4)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'valid': valid_loader,\n",
    "    'test' : test_loader\n",
    "}\n",
    "image_datasets = {\n",
    "    'train': train_sampler,\n",
    "    'valid': valid_sampler,\n",
    "    'test' : test_sampler\n",
    "}\n",
    "\n",
    "dataset_sizes ={\n",
    "    'train': len(image_datasets['train']),\n",
    "    'valid': len(image_datasets['valid']),\n",
    "    'test' : len(image_datasets['test'])\n",
    "}\n",
    "\n",
    "# dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "# print('train_class:' len(train_image_datasets.classes))\n",
    "\n",
    "print('train_size: ',dataset_sizes['train'], '\\nvalid_size: ',dataset_sizes['valid'], \n",
    "      '\\ntest_size : ',dataset_sizes['test'])\n",
    "# class_names = image_datasets['train'].classes\n",
    "# print(class_names)\n",
    "# print('len class: ', len(class_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResidualUnit import ResidualBlock\n",
    "from ASPP_edit_PLACE import ASPP_places\n",
    "# from attention_module import Attention_step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_place(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention_place, self).__init__()\n",
    "        self.begin_residual_blocks = nn.Sequential(\n",
    "            nn.Conv2d(3,64,kernel_size=7, stride = 2, padding = 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding = 1)\n",
    "        )#56x56\n",
    "        self.trunk_first_conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64,64, kernel_size=1)\n",
    "        )#56x56\n",
    "        self.trunk = nn.Sequential(\n",
    "            ResidualBlock(64, 256, 1),\n",
    "            ResidualBlock(256, 256, 1)\n",
    "        )#56x56\n",
    "        self.trunk_last_conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size = 1)\n",
    "        )#56x56\n",
    "        self.trunk_residual = nn.Sequential(\n",
    "            nn.Conv2d(64,256,1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "#             nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1)\n",
    "        )\n",
    "#         resnet = ResNet18()\n",
    "#         self.num_classes = len(class_names)\n",
    "#         self.resnet = nn.Sequential(*list(resnet.children())[:-2])#8x8\n",
    "\n",
    "        self.aspp = ASPP_places()\n",
    "        self.mask_first_conv = nn.Sequential(\n",
    "            nn.Conv2d(64, 96, kernel_size=1, stride = 2),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )#28x28\n",
    "        self._last_conv = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=1, stride = 2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512, 2048, kernel_size=1, stride = 2),\n",
    "            nn.BatchNorm2d(2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "#             nn.BatchNorm2d(512),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride = 2, padding = 1)\n",
    "        )#7x7\n",
    "        \n",
    "        \n",
    "        self.mpool = nn.Sequential(\n",
    "            nn.BatchNorm2d(2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "        )\n",
    "        self.fc = nn.Linear(2048, len(class_names_train))\n",
    "    def forward(self, x):\n",
    "        h = int(x.size()[2] / 4)\n",
    "        w = int(x.size()[3] / 4)\n",
    "#         print('h:',h, 'w:',w)\n",
    "        x1 = self.begin_residual_blocks(x)#56x56\n",
    "#         print(x1.shape)\n",
    "#         print(x1.shape)\n",
    "#################trunk_part#################\n",
    "        out_trunk1 = self.trunk_first_conv(x1)#56x56\n",
    "        out_trunk2 = self.trunk(out_trunk1)#56x56\n",
    "        out_trunk3 = self.trunk_last_conv(out_trunk2)#56x56\n",
    "#         out_trunk = F.upsample(out_trunk, size=(h,w), mode=\"bilinear\")#56x56x256\n",
    "        out_trunk4 = out_trunk3 + self.trunk_residual(x1)#56x56\n",
    "#         out_trunk = F.softmax(out_trunk)\n",
    "#################trunk_part#################        \n",
    "\n",
    "#################mask_part#################\n",
    "        feature_map = self.mask_first_conv(x1)#28x28x256\n",
    "        mask = self.aspp(feature_map)#28x28x256\n",
    "#         print(mask.shape)\n",
    "        mask = F.upsample(mask, size=(h, w), mode=\"bilinear\") #56x56x256\n",
    "#         mask = F.softmax(mask)\n",
    "#################mask_part#################\n",
    "        out1 = (1 + mask) * out_trunk4 #56x56x256\n",
    "#         print(out.shape)\n",
    "        out2 = self._last_conv(out1)#7x7x512\n",
    "#         print(out.shape)\n",
    "        out3 = self.mpool(out2)#1x1x512\n",
    "#         print(out.shape)\n",
    "        out = out3.view(out3.size(0),-1)\n",
    "#         print(out.shape)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, out_trunk1, out_trunk2, out_trunk3, out_trunk4, feature_map, mask, out1, out2, out3\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:         # Conv weight init\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:  # BatchNorm weight init\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Attention_place()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attention_place(\n",
       "  (begin_residual_blocks): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (trunk_first_conv): Sequential(\n",
       "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (trunk): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (trunk_last_conv): Sequential(\n",
       "    (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (trunk_residual): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (aspp): ASPP_places(\n",
       "    (conv_1x1_1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn_conv_1x1_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_3x3_dil6): Sequential(\n",
       "      (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_3x3_dil12): Sequential(\n",
       "      (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_3x3_dil18): Sequential(\n",
       "      (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_1x1_3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn_conv_1x1_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_1x1_4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (mask_first_conv): Sequential(\n",
       "    (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))\n",
       "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (_last_conv): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Conv2d(512, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
       "    (3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (mpool): Sequential(\n",
       "    (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  )\n",
       "  (fc): Linear(in_features=2048, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA, model\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "       BatchNorm2d-5           [-1, 64, 56, 56]             128\n",
      "              ReLU-6           [-1, 64, 56, 56]               0\n",
      "            Conv2d-7           [-1, 64, 56, 56]           4,160\n",
      "       BatchNorm2d-8           [-1, 64, 56, 56]             128\n",
      "              ReLU-9           [-1, 64, 56, 56]               0\n",
      "           Conv2d-10           [-1, 64, 56, 56]           4,096\n",
      "      BatchNorm2d-11           [-1, 64, 56, 56]             128\n",
      "             ReLU-12           [-1, 64, 56, 56]               0\n",
      "           Conv2d-13           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-14           [-1, 64, 56, 56]             128\n",
      "             ReLU-15           [-1, 64, 56, 56]               0\n",
      "           Conv2d-16          [-1, 256, 56, 56]          16,384\n",
      "           Conv2d-17          [-1, 256, 56, 56]          16,384\n",
      "    ResidualBlock-18          [-1, 256, 56, 56]               0\n",
      "      BatchNorm2d-19          [-1, 256, 56, 56]             512\n",
      "             ReLU-20          [-1, 256, 56, 56]               0\n",
      "           Conv2d-21           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-22           [-1, 64, 56, 56]             128\n",
      "             ReLU-23           [-1, 64, 56, 56]               0\n",
      "           Conv2d-24           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-25           [-1, 64, 56, 56]             128\n",
      "             ReLU-26           [-1, 64, 56, 56]               0\n",
      "           Conv2d-27          [-1, 256, 56, 56]          16,384\n",
      "    ResidualBlock-28          [-1, 256, 56, 56]               0\n",
      "      BatchNorm2d-29          [-1, 256, 56, 56]             512\n",
      "             ReLU-30          [-1, 256, 56, 56]               0\n",
      "           Conv2d-31          [-1, 256, 56, 56]          65,792\n",
      "           Conv2d-32          [-1, 256, 56, 56]          16,640\n",
      "      BatchNorm2d-33          [-1, 256, 56, 56]             512\n",
      "             ReLU-34          [-1, 256, 56, 56]               0\n",
      "           Conv2d-35           [-1, 96, 28, 28]           6,240\n",
      "      BatchNorm2d-36           [-1, 96, 28, 28]             192\n",
      "             ReLU-37           [-1, 96, 28, 28]               0\n",
      "           Conv2d-38          [-1, 128, 28, 28]          12,416\n",
      "      BatchNorm2d-39          [-1, 128, 28, 28]             256\n",
      "           Conv2d-40          [-1, 128, 28, 28]          12,416\n",
      "           Conv2d-41          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-42          [-1, 128, 28, 28]             256\n",
      "           Conv2d-43          [-1, 128, 28, 28]          12,416\n",
      "           Conv2d-44          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-45          [-1, 128, 28, 28]             256\n",
      "           Conv2d-46          [-1, 128, 28, 28]          12,416\n",
      "           Conv2d-47          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
      "           Conv2d-49          [-1, 256, 28, 28]         131,328\n",
      "      BatchNorm2d-50          [-1, 256, 28, 28]             512\n",
      "           Conv2d-51          [-1, 256, 28, 28]          65,792\n",
      "      ASPP_places-52          [-1, 256, 28, 28]               0\n",
      "           Conv2d-53          [-1, 512, 28, 28]         131,584\n",
      "      BatchNorm2d-54          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-55         [-1, 2048, 14, 14]       1,050,624\n",
      "      BatchNorm2d-56         [-1, 2048, 14, 14]           4,096\n",
      "             ReLU-57         [-1, 2048, 14, 14]               0\n",
      "        MaxPool2d-58           [-1, 2048, 7, 7]               0\n",
      "      BatchNorm2d-59           [-1, 2048, 7, 7]           4,096\n",
      "             ReLU-60           [-1, 2048, 7, 7]               0\n",
      "        AvgPool2d-61           [-1, 2048, 1, 1]               0\n",
      "           Linear-62                   [-1, 20]          40,980\n",
      "================================================================\n",
      "Total params: 2,171,764\n",
      "Trainable params: 2,171,764\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 159.46\n",
      "Params size (MB): 8.28\n",
      "Estimated Total Size (MB): 168.32\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lee/anaconda3/envs/pytorch1/lib/python3.6/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/lee/anaconda3/envs/pytorch1/lib/python3.6/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA, model\")\n",
    "    model.cuda() #after second other epoch model\n",
    "summary(model,(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, scheduler, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        since1 = time.time()\n",
    "        # Each epoch has a training and validation phase\n",
    "        train_batches = len(dataloaders['train'])\n",
    "        for phase in ['train','valid']:\n",
    "            \n",
    "            print(\"lr:\", optimizer.param_groups[0]['lr'])\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for i, data in enumerate(dataloaders[phase]):\n",
    "                if i % 100 == 0:\n",
    "                    print(\"\\rTraining batch {}/{}\".format(i, len(dataloaders[phase])), end='', flush=True)\n",
    "                # Use half training dataset\n",
    "                if i >= len(dataloaders[phase]):\n",
    "                    break    \n",
    "                inputs, labels = data\n",
    "                inputs, labels = Variable(inputs.cuda()),Variable(labels.cuda())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    out, out_trunk1, out_trunk2, out_trunk3, out_trunk4, feature_map, mask, out1, out2, out3 = model(inputs)\n",
    "                    _, preds = torch.max(out, 1)\n",
    "                    loss = criterion(out, labels)\n",
    "#                     print(loss)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar('data/train_loss_places', epoch_loss, epoch)\n",
    "                writer.add_scalar('data/train_acc_places', epoch_acc, epoch)\n",
    "            else:\n",
    "                writer.add_scalar('data/val_loss_places', epoch_loss, epoch)\n",
    "                writer.add_scalar('data/val_acc_places', epoch_acc, epoch)\n",
    "            for name, param in model.named_parameters():\n",
    "                writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
    "            time_elapsed1 = time.time() - since1\n",
    "            print('\\rEpoch process in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed1 // 60, time_elapsed1 % 60))\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} lr: {:.4f}'.format(phase, epoch_loss, \n",
    "                                                                  epoch_acc, optimizer.param_groups[0]['lr']))\n",
    "#             csvfile = open(os.path.join('./csv/resnet18/', '20190102resnet18_64_data_15_places_{}{}_class{}_epoch{}.csv'.format(optimizer_name, learning_rate, len(class_names), num_epochs)), 'a', newline='')\n",
    "#             csv_writer = csv.writer(csvfile, delimiter=';', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "#             csv_writer.writerow(['class', len(class_names), 'epoch', epoch, phase, epoch_loss, epoch_acc])\n",
    "#             csvfile.close()\n",
    "#             deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f} at {}'.format(best_acc, best_epoch+1))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 11m 11s\n",
      "train Loss: 1.7244 Acc: 0.4594 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 14m 21s\n",
      "valid Loss: 1.8863 Acc: 0.4427 lr: 0.0010\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 21s5\n",
      "train Loss: 1.3416 Acc: 0.5726 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 5m 0s\n",
      "valid Loss: 1.3825 Acc: 0.5620 lr: 0.0010\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 19s5\n",
      "train Loss: 1.2150 Acc: 0.6136 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 59s\n",
      "valid Loss: 1.2032 Acc: 0.6160 lr: 0.0010\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 21s5\n",
      "train Loss: 1.1272 Acc: 0.6406 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 56s\n",
      "valid Loss: 1.1865 Acc: 0.6191 lr: 0.0010\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 21s5\n",
      "train Loss: 1.0704 Acc: 0.6578 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 58s\n",
      "valid Loss: 1.8137 Acc: 0.4765 lr: 0.0010\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 1.0171 Acc: 0.6744 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 1.0451 Acc: 0.6615 lr: 0.0010\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.9771 Acc: 0.6885 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 59s\n",
      "valid Loss: 1.0310 Acc: 0.6745 lr: 0.0010\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.9415 Acc: 0.6982 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 52s\n",
      "valid Loss: 1.0675 Acc: 0.6661 lr: 0.0010\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.9168 Acc: 0.7065 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.9640 Acc: 0.6875 lr: 0.0010\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.8870 Acc: 0.7155 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 1.0660 Acc: 0.6675 lr: 0.0010\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.8608 Acc: 0.7216 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 52s\n",
      "valid Loss: 1.0491 Acc: 0.6723 lr: 0.0010\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 19s5\n",
      "train Loss: 0.8394 Acc: 0.7310 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 56s\n",
      "valid Loss: 1.0582 Acc: 0.6601 lr: 0.0010\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.8189 Acc: 0.7353 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.9314 Acc: 0.7065 lr: 0.0010\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.8049 Acc: 0.7404 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.9163 Acc: 0.7053 lr: 0.0010\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.7793 Acc: 0.7488 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 52s\n",
      "valid Loss: 0.9137 Acc: 0.7067 lr: 0.0010\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.7648 Acc: 0.7530 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 1.0189 Acc: 0.6817 lr: 0.0010\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.7514 Acc: 0.7563 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.8808 Acc: 0.7207 lr: 0.0010\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.7356 Acc: 0.7618 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.8843 Acc: 0.7216 lr: 0.0010\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.7155 Acc: 0.7683 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.8448 Acc: 0.7287 lr: 0.0010\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.7046 Acc: 0.7705 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 55s\n",
      "valid Loss: 0.9724 Acc: 0.6948 lr: 0.0010\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.6954 Acc: 0.7728 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.9516 Acc: 0.6970 lr: 0.0010\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.6786 Acc: 0.7786 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 52s\n",
      "valid Loss: 0.8477 Acc: 0.7335 lr: 0.0010\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.6664 Acc: 0.7838 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 55s\n",
      "valid Loss: 0.8936 Acc: 0.7252 lr: 0.0010\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.6607 Acc: 0.7835 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.9377 Acc: 0.7068 lr: 0.0010\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.6466 Acc: 0.7904 lr: 0.0010\n",
      "lr: 0.001\n",
      "Epoch process in 4m 52s\n",
      "valid Loss: 0.9074 Acc: 0.7187 lr: 0.0010\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "lr: 0.001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.4904 Acc: 0.8439 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.7403 Acc: 0.7653 lr: 0.0001\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 16s5\n",
      "train Loss: 0.4424 Acc: 0.8600 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 52s\n",
      "valid Loss: 0.7400 Acc: 0.7676 lr: 0.0001\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.4202 Acc: 0.8662 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.7533 Acc: 0.7643 lr: 0.0001\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.4014 Acc: 0.8733 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.7533 Acc: 0.7665 lr: 0.0001\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.3853 Acc: 0.8765 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.7580 Acc: 0.7656 lr: 0.0001\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.3735 Acc: 0.8827 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 50s\n",
      "valid Loss: 0.7672 Acc: 0.7648 lr: 0.0001\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.3579 Acc: 0.8876 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.7644 Acc: 0.7660 lr: 0.0001\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.3480 Acc: 0.8893 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.7803 Acc: 0.7619 lr: 0.0001\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.3373 Acc: 0.8940 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 52s\n",
      "valid Loss: 0.7856 Acc: 0.7627 lr: 0.0001\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.3259 Acc: 0.8978 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 52s\n",
      "valid Loss: 0.7878 Acc: 0.7627 lr: 0.0001\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.3128 Acc: 0.9022 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.8085 Acc: 0.7601 lr: 0.0001\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.3036 Acc: 0.9048 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.8069 Acc: 0.7595 lr: 0.0001\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.2928 Acc: 0.9080 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.8144 Acc: 0.7589 lr: 0.0001\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.2835 Acc: 0.9125 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 5m 0s\n",
      "valid Loss: 0.8180 Acc: 0.7593 lr: 0.0001\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.2730 Acc: 0.9162 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.8264 Acc: 0.7582 lr: 0.0001\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.2644 Acc: 0.9190 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.8359 Acc: 0.7553 lr: 0.0001\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.2557 Acc: 0.9218 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 55s\n",
      "valid Loss: 0.8384 Acc: 0.7558 lr: 0.0001\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.2461 Acc: 0.9253 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.8520 Acc: 0.7542 lr: 0.0001\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.2376 Acc: 0.9290 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.8544 Acc: 0.7567 lr: 0.0001\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.2265 Acc: 0.9325 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.8729 Acc: 0.7529 lr: 0.0001\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.2208 Acc: 0.9341 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.8801 Acc: 0.7537 lr: 0.0001\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "lr: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.2116 Acc: 0.9379 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.8974 Acc: 0.7520 lr: 0.0001\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.2051 Acc: 0.9397 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.8933 Acc: 0.7529 lr: 0.0001\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1975 Acc: 0.9426 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 52s\n",
      "valid Loss: 0.9083 Acc: 0.7482 lr: 0.0001\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1899 Acc: 0.9452 lr: 0.0001\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.9196 Acc: 0.7512 lr: 0.0001\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "lr: 0.0001\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1616 Acc: 0.9564 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 55s\n",
      "valid Loss: 0.9089 Acc: 0.7520 lr: 0.0000\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1571 Acc: 0.9592 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.9107 Acc: 0.7512 lr: 0.0000\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1552 Acc: 0.9594 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 52s\n",
      "valid Loss: 0.9114 Acc: 0.7525 lr: 0.0000\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1530 Acc: 0.9608 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.9109 Acc: 0.7525 lr: 0.0000\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1512 Acc: 0.9612 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.9077 Acc: 0.7530 lr: 0.0000\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1481 Acc: 0.9631 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.9151 Acc: 0.7517 lr: 0.0000\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1477 Acc: 0.9628 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 55s\n",
      "valid Loss: 0.9182 Acc: 0.7515 lr: 0.0000\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1464 Acc: 0.9640 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 49s\n",
      "valid Loss: 0.9255 Acc: 0.7520 lr: 0.0000\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1441 Acc: 0.9640 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 50s\n",
      "valid Loss: 0.9034 Acc: 0.7538 lr: 0.0000\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1432 Acc: 0.9647 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.9153 Acc: 0.7505 lr: 0.0000\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1429 Acc: 0.9643 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 52s\n",
      "valid Loss: 0.9189 Acc: 0.7498 lr: 0.0000\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1426 Acc: 0.9648 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 52s\n",
      "valid Loss: 0.9134 Acc: 0.7518 lr: 0.0000\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1406 Acc: 0.9653 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.9230 Acc: 0.7503 lr: 0.0000\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1382 Acc: 0.9661 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.9187 Acc: 0.7513 lr: 0.0000\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1393 Acc: 0.9664 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.9322 Acc: 0.7523 lr: 0.0000\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1362 Acc: 0.9675 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.9192 Acc: 0.7511 lr: 0.0000\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1360 Acc: 0.9674 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.9213 Acc: 0.7512 lr: 0.0000\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1370 Acc: 0.9669 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.9248 Acc: 0.7518 lr: 0.0000\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1347 Acc: 0.9670 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.9207 Acc: 0.7531 lr: 0.0000\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1317 Acc: 0.9687 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.9335 Acc: 0.7520 lr: 0.0000\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1329 Acc: 0.9678 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.9283 Acc: 0.7520 lr: 0.0000\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1321 Acc: 0.9682 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 50s\n",
      "valid Loss: 0.9305 Acc: 0.7518 lr: 0.0000\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1310 Acc: 0.9695 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.9394 Acc: 0.7495 lr: 0.0000\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1298 Acc: 0.9694 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 52s\n",
      "valid Loss: 0.9267 Acc: 0.7513 lr: 0.0000\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1279 Acc: 0.9704 lr: 0.0000\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 52s\n",
      "valid Loss: 0.9313 Acc: 0.7521 lr: 0.0000\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "lr: 1.0000000000000003e-05\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1258 Acc: 0.9705 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.9340 Acc: 0.7509 lr: 0.0000\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1251 Acc: 0.9715 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.9269 Acc: 0.7524 lr: 0.0000\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1252 Acc: 0.9715 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.9378 Acc: 0.7506 lr: 0.0000\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1253 Acc: 0.9708 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 50s\n",
      "valid Loss: 0.9243 Acc: 0.7507 lr: 0.0000\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1252 Acc: 0.9709 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.9376 Acc: 0.7524 lr: 0.0000\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1249 Acc: 0.9713 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 55s\n",
      "valid Loss: 0.9268 Acc: 0.7512 lr: 0.0000\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1253 Acc: 0.9704 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.9378 Acc: 0.7517 lr: 0.0000\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1257 Acc: 0.9713 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.9427 Acc: 0.7516 lr: 0.0000\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1242 Acc: 0.9716 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.9263 Acc: 0.7513 lr: 0.0000\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1253 Acc: 0.9710 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.9366 Acc: 0.7515 lr: 0.0000\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1249 Acc: 0.9719 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch process in 4m 57s\n",
      "valid Loss: 0.9283 Acc: 0.7511 lr: 0.0000\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1233 Acc: 0.9722 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 51s\n",
      "valid Loss: 0.9381 Acc: 0.7499 lr: 0.0000\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1235 Acc: 0.9717 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 52s\n",
      "valid Loss: 0.9225 Acc: 0.7503 lr: 0.0000\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1232 Acc: 0.9730 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 56s\n",
      "valid Loss: 0.9355 Acc: 0.7517 lr: 0.0000\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1237 Acc: 0.9712 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.9272 Acc: 0.7519 lr: 0.0000\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1239 Acc: 0.9722 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.9280 Acc: 0.7523 lr: 0.0000\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1229 Acc: 0.9711 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.9303 Acc: 0.7532 lr: 0.0000\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1223 Acc: 0.9724 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.9307 Acc: 0.7515 lr: 0.0000\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1235 Acc: 0.9715 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 57s\n",
      "valid Loss: 0.9422 Acc: 0.7521 lr: 0.0000\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1235 Acc: 0.9718 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.9406 Acc: 0.7511 lr: 0.0000\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1222 Acc: 0.9719 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.9337 Acc: 0.7509 lr: 0.0000\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1226 Acc: 0.9720 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 54s\n",
      "valid Loss: 0.9288 Acc: 0.7512 lr: 0.0000\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1215 Acc: 0.9734 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 52s\n",
      "valid Loss: 0.9317 Acc: 0.7528 lr: 0.0000\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 18s5\n",
      "train Loss: 0.1225 Acc: 0.9729 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 53s\n",
      "valid Loss: 0.9383 Acc: 0.7505 lr: 0.0000\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 17s5\n",
      "train Loss: 0.1217 Acc: 0.9731 lr: 0.0000\n",
      "lr: 1.0000000000000002e-06\n",
      "Epoch process in 4m 56s\n",
      "valid Loss: 0.9348 Acc: 0.7507 lr: 0.0000\n",
      "\n",
      "Training complete in 498m 4s\n",
      "Best val Acc: 0.767572 at 27\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "lr = 0.001  # 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n",
    "total_epoch = 100\n",
    "model_train = train_model(model, scheduler, criterion, optimizer, num_epochs=total_epoch)\n",
    "torch.save(model_train.state_dict(), './Trained/place_50_adam.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
